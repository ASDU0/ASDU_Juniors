# Visi√≥n por Computador: Teor√≠a Fundamental (Resumen)

## 1Ô∏è‚É£ ¬øQu√© es la Visi√≥n por Computador?
Es un campo de la inteligencia artificial que entrena a las computadoras para **interpretar y entender el mundo visual** (im√°genes, videos). El objetivo es replicar la capacidad humana de percibir objetos, personas, escenas y contextos, pero a trav√©s de algoritmos y modelos matem√°ticos.

**Analog√≠a:** As√≠ como nuestros ojos env√≠an se√±ales al cerebro para que las procese, en visi√≥n artificial, una c√°mara captura p√≠xeles y un algoritmo los procesa para extraer informaci√≥n significativa.

---

## 2Ô∏è‚É£ Niveles de Procesamiento Visual
El an√°lisis de im√°genes se puede dividir en tres niveles jer√°rquicos:

### a) Procesamiento de Bajo Nivel
- **Qu√© hace:** Opera directamente sobre los p√≠xeles.
- **Tareas:**
    - **Filtrado:** Suavizar (desenfocar) o resaltar bordes.
    - **Detecci√≥n de bordes:** Identificar cambios bruscos de intensidad (ej. algoritmo Canny).
    - **Operaciones morfol√≥gicas:** Erosi√≥n y dilataci√≥n para limpiar ruido.

### b) Procesamiento de Nivel Intermedio
- **Qu√© hace:** Agrupa p√≠xeles para formar estructuras.
- **Tareas:**
    - **Segmentaci√≥n:** Dividir la imagen en regiones de inter√©s (ej. separar el fondo del objeto).
    - **Extracci√≥n de caracter√≠sticas:** Identificar formas, texturas o colores espec√≠ficos.

### c) Procesamiento de Alto Nivel
- **Qu√© hace:** Asigna significado sem√°ntico a la imagen.
- **Tareas:**
    - **Clasificaci√≥n:** ¬øQu√© objeto es este? (ej. "es un gato").
    - **Detecci√≥n:** ¬øD√≥nde est√° el objeto? (dibuja un recuadro a su alrededor).
    - **Reconocimiento:** ¬øQui√©n es esta persona? (identificaci√≥n facial).

---

## 3Ô∏è‚É£ Tareas Principales en Visi√≥n por Computador

### üì∏ Clasificaci√≥n de Im√°genes
- **Objetivo:** Dado un input (imagen), asignarle una √∫nica etiqueta de clase.
- **Ejemplo:** Esta foto contiene un "perro".

### üîç Detecci√≥n de Objetos
- **Objetivo:** Identificar *m√∫ltiples* objetos dentro de una misma imagen y ubicarlos espacialmente con *bounding boxes* (cajas delimitadoras).
- **Ejemplo:** Encontrar todos los coches y peatones en una foto de calle.

### üé® Segmentaci√≥n Sem√°ntica
- **Objetivo:** Clasificar *cada p√≠xel* de la imagen en una categor√≠a. No distingue instancias (todos los coches son "coche", sin diferenciar coche1 de coche2).
- **Ejemplo:** Pintar la carretera de gris, el cielo de azul y los peatones de rojo.

### üß© Segmentaci√≥n de Instancias
- **Objetivo:** Es la combinaci√≥n de detecci√≥n + segmentaci√≥n. Clasifica cada p√≠xel *y* distingue entre instancias individuales.
- **Ejemplo:** Pintar cada persona de un color diferente, aunque est√©n superpuestas.

---

## 4Ô∏è‚É£ Evoluci√≥n T√©cnica: De lo Cl√°sico al Deep Learning

### üßÆ Enfoque Cl√°sico (Tradicional)
Se basaba en ingenier√≠a de caracter√≠sticas hechas a mano.
1.  **Extracci√≥n de Caracter√≠sticas:** Algoritmos como SIFT (Scale-Invariant Feature Transform) o HOG (Histogram of Oriented Gradients) detectaban bordes, esquinas y texturas.
2.  **Clasificaci√≥n:** Esas caracter√≠sticas se pasaban a un clasificador cl√°sico como **SVM (Support Vector Machine)** o Random Forest.

**Limitaci√≥n:** Depend√≠an del conocimiento del experto para dise√±ar las caracter√≠sticas; no generalizaban bien a escenarios no vistos.

### ü§ñ Enfoque de Deep Learning (Actual)
Las redes neuronales, especialmente las **Redes Neuronales Convolucionales (CNNs)** , automatizan todo el proceso.
1.  **Aprendizaje de Caracter√≠sticas:** La red aprende autom√°ticamente qu√© bordes, texturas o formas son relevantes para la tarea.
2.  **End-to-End:** La imagen entra y la predicci√≥n sale, sin pasos intermedios manuales.

**Ventaja:** Mucho mayor precisi√≥n y robustez, capaces de aprender representaciones jer√°rquicas complejas.

---

## 5Ô∏è‚É£ Arquitectura Clave: Redes Neuronales Convolucionales (CNN)
Son el pilar del Deep Learning aplicado a im√°genes.

### Componentes Principales
1.  **Capas de Convoluci√≥n:** Aplican filtros (kernels) a la imagen para extraer caracter√≠sticas. El filtro "desliza" sobre la imagen produciendo un *mapa de caracter√≠sticas*.
2.  **Capas de Pooling (Submuestreo):** Reducen la dimensionalidad de los mapas de caracter√≠sticas (ej. Max Pooling, que se queda con el valor m√°ximo de una regi√≥n). Sirve para hacer el modelo m√°s robusto a peque√±as variaciones.
3.  **Capas Fully Connected (FC):** Al final de la red, "aplanan" la informaci√≥n y act√∫an como un clasificador tradicional para dar el resultado final.

### Arquitectos CNN Populares
- **AlexNet:** Pionera que gan√≥ ImageNet en 2012.
- **VGG16:** Demostr√≥ que la profundidad (muchas capas) mejora el rendimiento.
- **ResNet:** Introdujo las "conexiones residuales" (saltos) para poder entrenar redes extremadamente profundas (>100 capas) sin perder precisi√≥n.
- **YOLO (You Only Look Once):** Arquitectura famosa por su velocidad en detecci√≥n de objetos en tiempo real.

---

## 6Ô∏è‚É£ Desaf√≠os Actuales y Conceptos Clave
- **Iluminaci√≥n y Escala:** Un objeto se ve diferente con luz solar que con luz artificial, o de cerca que de lejos. Los modelos deben ser **invariantes** a estos cambios.
- **Oclusi√≥n:** Cuando el objeto est√° parcialmente tapado por otro.
- **Punto de Vista:** Un objeto visto desde un √°ngulo puede parecer muy diferente que desde otro.
- **Datos Etiquetados:** El Deep Learning requiere grandes vol√∫menes de datos anotados manualmente, lo cual es costoso y lento (de ah√≠ el auge del *Aprendizaje Semi-Supervisado* y *Self-Supervisado*).
- **Aprendizaje por Transferencia (*Transfer Learning*):** T√©cnica estrella. Se toma un modelo ya entrenado (ej. en ImageNet) y se re-entrena (*fine-tuning*) la √∫ltima capa para una tarea espec√≠fica con pocos datos. Ahorra tiempo y recursos.

---

## üìå Conclusi√≥n
La Visi√≥n por Computador ha evolucionado de ser un sistema de reglas hechas a mano a un campo dominado por el aprendizaje profundo. Hoy permite desde el filtro de una c√°mara de smartphone hasta coches aut√≥nomos que entienden su entorno en tiempo real. La clave est√° en entrenar modelos capaces de **generalizar** el conocimiento visual a un mundo infinitamente variado.


## 7Ô∏è‚É£ Librer√≠as Esenciales para Visi√≥n por Computador

Para implementar sistemas de visi√≥n artificial, los desarrolladores utilizan un ecosistema de librer√≠as que van desde el procesamiento cl√°sico hasta el deep learning de √∫ltima generaci√≥n.

### üü¢ Librer√≠as Fundamentales (Open Source)

| Librer√≠a | Descripci√≥n | Casos de Uso | Enlace |
| :--- | :--- | :--- | :--- |
| **OpenCV (Open Source Computer Vision Library)** | Es la librer√≠a est√°ndar de la industria. Contiene m√°s de **2500 algoritmos optimizados** para tareas de visi√≥n en tiempo real [citation:5][citation:7]. Soporta C++, Python, Java y est√° optimizada para ejecuci√≥n en CPU. | - Detecci√≥n de rostros y objetos <br>- Procesamiento de im√°genes (filtros, transformaciones) <br>- Calibraci√≥n de c√°maras <br>- Seguimiento de movimiento | [OpenCV.org](https://opencv.org) |
| **Scikit-image** | Construida sobre SciPy, es excelente para tareas de procesamiento cl√°sico. Es m√°s f√°cil de usar que OpenCV para principiantes, pero menos eficiente para tiempo real. | - Segmentaci√≥n (Superp√≠xeles, cuencas) <br>- Extracci√≥n de caracter√≠sticas <br>- Restauraci√≥n de im√°genes | [Scikit-image.org](https://scikit-image.org) |
| **PIL / Pillow** | La librer√≠a amigable para operaciones b√°sicas de imagen: abrir, manipular, recortar, redimensionar y guardar [citation:8]. | - Preprocesamiento r√°pido <br>- Conversi√≥n de formatos <br>- Generaci√≥n de thumbnails | [Python-Pillow.org](https://python-pillow.org) |

### üîµ Librer√≠as de Deep Learning

| Librer√≠a | Descripci√≥n | Cu√°ndo Usarla |
| :--- | :--- | :--- |
| **PyTorch (Meta/FAIR)** | La favorita en investigaci√≥n. Ofece gr√°ficos de computaci√≥n din√°micos, lo que facilita la depuraci√≥n y experimentaci√≥n [citation:9]. | - Investigaci√≥n acad√©mica <br>- Modelos personalizados complejos <br>- NLP + Visi√≥n (multimodal) |
| **TensorFlow / Keras (Google)** | M√°s estable en producci√≥n. Keras es su API de alto nivel, ideal para principiantes. TensorFlow Serving permite desplegar modelos en servidores. | - Despliegue industrial <br>- Aplicaciones m√≥viles (TensorFlow Lite) <br>- Prototipado r√°pido con Keras |
| **Create ML (Apple)** | Herramienta de Apple para entrenar modelos en Mac sin necesidad de ser experto en ML. Permite entrenar modelos de *object tracking* para visionOS desde la l√≠nea de comandos [citation:2]. | - Aplicaciones para Apple Vision Pro, iOS y macOS. <br>- Flujos de trabajo integrados con Xcode. |

### üü£ Librer√≠as Especializadas por Tarea

#### üöÄ Modelos Pre-entrenados (SOTA)

- **Ultralytics YOLO (You Only Look Once):** Es el est√°ndar de facto para detecci√≥n de objetos en tiempo real.
    - **Novedad:** La versi√≥n **YOLO26** (lanzada en 2026) elimina la necesidad de post-procesamiento (Non-Maximum Suppression - NMS), lo que lo hace hasta **43% m√°s r√°pido en CPUs** y nativamente compatible con dispositivos edge [citation:10]. Soporta detecci√≥n, segmentaci√≥n, clasificaci√≥n, pose estimation y tracking.
- **Hugging Face Transformers:** Ofrece acceso a modelos de √∫ltima generaci√≥n como **DETR** (Detecci√≥n con Transformers), **DINO** y **SAM (Segment Anything Model)** de Meta.

#### ‚ö° Aceleraci√≥n GPU

- **CV-CUDA (NVIDIA):** Librer√≠a open-source para acelerar pipelines completos de procesamiento de im√°genes en la nube usando GPUs [citation:3].

---

## 8Ô∏è‚É£ Pasos a Seguir: Pipeline Completo de un Proyecto

Desarrollar un sistema de visi√≥n por computador no es solo entrenar un modelo. Sigue este flujo de trabajo profesional para garantizar el √©xito [citation:6][citation:9].

### Fase 1: Definici√≥n y Recolecci√≥n de Datos
1.  **Definir el Objetivo:** ¬øClasificaci√≥n, detecci√≥n, segmentaci√≥n o tracking?
2.  **Recolectar Im√°genes:** Captura datos representativos del mundo real.
    - *Ejemplo:* Usar una c√°mara RTSP para capturar 1 frame por segundo y almacenarlos [citation:6].
    - **Herramientas:** `OpenCV` (`cv2.VideoCapture`) para capturar de c√°maras, scripts de descarga web.
3.  **Calidad sobre Cantidad:** Filtra im√°genes borrosas, oscuras o corruptas.
    - **Acci√≥n:** Ejecutar un an√°lisis de calidad previo (*Quality Analyzer*) para depurar el dataset [citation:9].

### Fase 2: Curaci√≥n y Etiquetado
4.  **Curaci√≥n de Datos:** Selecciona el subconjunto m√°s valioso para etiquetar. No necesitas etiquetar todo; a veces con un 25% de las im√°genes bien seleccionadas es suficiente [citation:6].
    - **T√©cnica:** Usar *embeddings* visuales para seleccionar la mayor diversidad posible (Auto-Curate).
5.  **Anotaci√≥n (Labeling):** Dibuja las cajas (bounding boxes) o m√°scaras sobre los objetos.
    - **Herramientas:** Superb AI, LabelImg, CVAT, Roboflow.
    - **Optimizaci√≥n:** Usa *Auto-Labeling*: un modelo pre-entrenado etiqueta autom√°ticamente y un humano solo revisa y corrige [citation:6].

### Fase 3: Entrenamiento del Modelo
6.  **Preparar el Entorno:** Configura un entorno aislado.
    - **Herramientas:** Anaconda o Virtualenv.
    - **Comando:**
        ```bash
        conda create -n vision_project python=3.10 -y
        conda activate vision_project
        pip install torch torchvision opencv-python ultralytics [citation:9]
        ```
7.  **Seleccionar Arquitectura:** Elige el modelo base.
    - *Si buscas velocidad:* **YOLO26** (nano o small) [citation:10].
    - *Si buscas precisi√≥n:* **DETR** o **Mask2Former**.
8.  **Entrenar (Transfer Learning):** No entrenes desde cero. Usa un modelo pre-entrenado (ej. en ImageNet) y aj√∫stalo (*fine-tuning*) con tus datos.
    - **Configuraci√≥n:** Define √©pocas, tama√±o de lote (*batch size*) y tasa de aprendizaje.
9.  **Evaluar:** Revisa las m√©tricas (Precisi√≥n, Recall, mAP - mean Average Precision). Usa **Matrices de Confusi√≥n** y revisa los **Falsos Positivos** de alta confianza para diagnosticar errores [citation:6].

### Fase 4: Despliegue e Inferencia
10. **Exportar el Modelo:** Convierte el modelo al formato √≥ptimo para tu hardware.
    - **Formatos:** ONNX (intercambio universal), TensorRT (NVIDIA), CoreML (Apple), OpenVINO (Intel) [citation:10].
11. **Crear el Pipeline de Inferencia:**
    - **C√≥digo de producci√≥n:** Un script que recibe im√°genes (de una c√°mara en vivo o archivo), las preprocesa, las pasa al modelo y procesa los resultados.
    - **Ejemplo conceptual:**
        ```python
        # 1. Cargar modelo exportado
        # 2. Capturar frame (cap.read() de OpenCV)
        # 3. Preprocesar (redimensionar, normalizar)
        # 4. Inferencia (modelo.predict(frame))
        # 5. Post-procesar (filtrar por confianza, dibujar bounding boxes)
        # 6. Mostrar o guardar resultado
        ```
12. **Iterar:** Los datos de producci√≥n (im√°genes con baja confianza) deben realimentar el dataset para una nueva ronda de entrenamiento, mejorando el modelo continuamente (MLOps) [citation:6].

---

##  Ejemplo de Stack Tecnol√≥gico (Caso Real)
Basado en un pipeline para detecci√≥n de objetos en investigaci√≥n [citation:9]:

- **Gestor de Entorno:** Anaconda
- **Framework DL:** PyTorch (con soporte CUDA)
- **Modelo:** DINO / Grounding DINO (detecci√≥n por texto)
- **Procesamiento:** OpenCV, Pillow-SIMD (optimizado)
- **Utilidades:** Pandas (para reportes CSV), tqdm (barras de progreso), PyYAML (configuraci√≥n)
- **Hardware:** GPU NVIDIA (RTX serie 20-40) para aceleraci√≥n [citation:9].